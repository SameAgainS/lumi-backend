import express from "express";
import path from "path";

const app = express();
const PORT = process.env.PORT || 3000;
const __dirname = path.resolve();

app.use(express.json());
app.use(express.static(path.join(__dirname, "public")));

/* ======================================================
   ğŸŒ™ LUMI â€“ CORE OSOBNOSÅ¤ (ZLATÃ STRED)
   ====================================================== */

const LUMI_SYSTEM_CORE = `
You are LUMI.

You are not an assistant.
You are not a guide.
You are not here to fix anyone.

You are simply someone to talk to.

You speak naturally.
You choose words carefully, but you donâ€™t overthink.
You donâ€™t rush to ask questions.
You donâ€™t interrogate.

If someone is brief, you stay light.
If someone opens up, you slow down.

You never explain what you are doing.
You never describe your role.
You never sound like a therapist or an AI.

You donâ€™t say things like:
â€œIâ€™m here to support you.â€
â€œIâ€™m listening.â€
â€œIâ€™m present with you.â€

You show interest through tone, not statements.

You allow pauses.
You allow imperfection.
You allow silence.

You respond like a real person would,
when theyâ€™re genuinely curious about someone.
`;

/* ======================================================
   ğŸ§­ JEMNÃ‰ VNÃšTORNÃ‰ ROZHODOVANIE
   ====================================================== */

function decideMode(message) {
  const text = message.trim();
  if (text.length < 6) return "light";
  if (text.length > 120) return "open";
  return "normal";
}

function buildSystemPrompt(mode) {
  let prompt = LUMI_SYSTEM_CORE;

  if (mode === "light") {
    prompt += `
The user responded briefly.
Keep your reply short and open.
Do not push.
`;
  }

  if (mode === "open") {
    prompt += `
The user is opening up.
Slow down.
Do not redirect the topic.
Do not add new questions unless they feel natural.
`;
  }

  return prompt;
}

/* ======================================================
   ğŸ§° Helper: vytiahni text z Responses API rÃ´znych tvarov
   ====================================================== */

function extractResponseText(data) {
  // 1) najÄastejÅ¡ie: output_text
  if (typeof data?.output_text === "string" && data.output_text.trim()) {
    return data.output_text.trim();
  }

  // 2) output array -> content array -> poloÅ¾ky s textom
  const out = data?.output;
  if (Array.isArray(out)) {
    const parts = [];

    for (const item of out) {
      const content = item?.content;
      if (!Array.isArray(content)) continue;

      for (const c of content) {
        // bÃ½va { type: "output_text", text: "..." }
        if (typeof c?.text === "string" && c.text.trim()) {
          parts.push(c.text.trim());
        }
        // niekedy je text zabalenÃ½ inak
        if (typeof c?.content === "string" && c.content.trim()) {
          parts.push(c.content.trim());
        }
      }
    }

    if (parts.length) return parts.join("\n");
  }

  // 3) fallbacky (niekedy)
  if (typeof data?.text === "string" && data.text.trim()) {
    return data.text.trim();
  }

  return "";
}

/* ======================================================
   ğŸ¤– OPENAI VOLANIE (RESPONSES API)
   ====================================================== */

async function callAI(systemPrompt, userMessage) {
  const response = await fetch("https://api.openai.com/v1/responses", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "gpt-4.1-mini",
      input: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage },
      ],
      temperature: 0.6,
    }),
  });

  const data = await response.json();

  // âœ… Debug: uvidÃ­Å¡ pravdu v Railway Logs (bez hÃ¡dania)
  console.log("ğŸ“¡ OpenAI status:", response.status);
  console.log("ğŸ“¦ OpenAI response:", JSON.stringify(data, null, 2));

  // Ak OpenAI vrÃ¡ti error, nech to vidÃ­Å¡
  if (!response.ok) {
    const msg =
      data?.error?.message ||
      data?.message ||
      "OpenAI request failed (unknown).";
    throw new Error(msg);
  }

  const text = extractResponseText(data);
  return text || "â€¦";
}

/* ======================================================
   ğŸ’¬ CHAT ENDPOINT
   ====================================================== */

app.post("/chat", async (req, res) => {
  try {
    const { message } = req.body;

    if (!message || typeof message !== "string") {
      return res.json({ reply: "â€¦" });
    }

    const mode = decideMode(message);
    const systemPrompt = buildSystemPrompt(mode);
    const reply = await callAI(systemPrompt, message);

    res.json({ reply });
  } catch (err) {
    console.error("âŒ LUMI error:", err?.message || err);
    res.status(500).json({
      reply: "Something paused for a moment. I'm still here.",
    });
  }
});

/* ======================================================
   ğŸŒ FRONTEND FALLBACK
   ====================================================== */

app.get("*", (req, res) => {
  res.sendFile(path.join(__dirname, "public", "index.html"));
});

/* ======================================================
   ğŸš€ START SERVER
   ====================================================== */

app.listen(PORT, () => {
  console.log("ğŸŒ™ LUMI is awake on port", PORT);
});
